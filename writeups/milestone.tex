\documentclass{article} % For LaTeX2e
\usepackage{nips13submit_e,times}
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage{graphicx}
\usepackage{url}
\usepackage{placeins}
\usepackage{fancyvrb}
\usepackage[font={small,it},width=5in]{caption}
%\documentstyle[nips13submit_09,times,art10]{article} % For LaTeX 2.09


\title{CS 229 Milestone}

\author{Matthew Staib, Lennart Jansson, and Edward Dai}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}

\maketitle

\section{A short note about our topic}
Originally, we were planning to classify popular music by country of origin
using audio features. For example, we intended to cluster based on these
features and hoped to observe clusters corresponding to geographic origin.
However, after some reconsidering, we decided that this was infeasible since we
expected similarity between songs to be more closely tied to genre and other
factors instead of country of origin. We also had problems finding a large
dataset where we would have been able to choose the audio features ourselves
(e.g. The Million Song Dataset is quite vast and has audio features, but not the
original audio).

We still wanted to work on a project related to music and music analysis, but
decided that it would be more feasible to consider a problem with a cleaner
dataset. One of our group members had previously experimented with a dataset of
folk dance music where melodies are stored in a commonly used score notation
(ABC notation).

\section{Introduction}
Most folk dance music contains two musical themes; the tune begins with one
musical theme which is usually repeated, then progresses to another theme with
similar musical structure and motives, which is usually also repeated. The first
section is typically called the $A$ section while the second is called the $B$
section. Our goal is to understand, at a quantitative level, the relationship
between $A$ sections and $B$ sections. In the long term, for example, we want to
be able to, given an $A$ section, automatically generate a musically appropriate
$B$ section.

In working towards this goal, we need to understand both the relationship
between the $A$ and $B$ section of a given folk song as well as the differences
between $A$ and $B$ sections of such music in general. 

\section{Dataset}

%TODO: Maybe do something with citing?
We are using the tunes dataset from The Session (\texttt{thesession.org}). The
Session is an online community of people who are interested in playing Irish
folk music and cataloguing traditional Irish tunes for others to learn. These
tunes include various dance forms, such as jigs, reels, waltzes, and slides.
Available on their website is a set of roughly 21 thousand dance tune settings
in ABC notation, a human-readable symbolic music data format in plain text. The
ABC files are easily parsed and manipulated symbolically for feature extraction.
\FloatBarrier
\begin{figure}[t]
  \begin{center}
  \begin{BVerbatim}
X: 1
T: Drowsy Maggie
R: reel
M: 4/4
L: 1/8
K:Edor
|:E2BE dEBE|E2BE AFDF|E2BE dEBE|BABc dAFD:|
K:D
d2fd c2ec|defg afge|d2fd c2ec|BABc dAFA|
d2fd c2ec|defg afge|afge fdec|BABc dAFD|
  \end{BVerbatim}
  \end{center}
  \caption{\textit{Drowsy Maggie}, an example of a tune in ABC notation from
  \texttt{thesession.org}.}
\end{figure}

\begin{figure}[t]
  \begin{center}
    \includegraphics[width=5in]{drowsymaggie.png}
  \end{center}
  \caption{A rendering of \textit{Drowsy Maggie} in standard musical notation, for
  comparison with ABC notation. The $A$ section of this tune can be seen in the
first line, while the $B$ section spans the second and third lines. The $A$ and
$B$ sections are the same length since the first four bars are repeated---both
are eight bars long when performed. Note that this tune, like many others, has
four-bar phrases, which supports the heuristic we are using for splitting into
$A$ and $B$ sections.}
  \label{fig:drowsymusic}
\end{figure}
%\FloatBarrier

\section{Feature Extraction}

We first use an ABC parser to turn the tunes in ABC notation into manipulable
datatypes of bars and notes. For feature extraction, we count frequencies of
$n$-grams of note pitches up to $n=3$, which gives information about the
characteristic pitch contours of the individual tunes.

We are not currently using rhythm information of notes, nor are we considering
the particular octave or accidental inflection of pitches. This is a very basic
feature extraction scheme and we hope to extend our feature extraction soon to
include this other information, which may be useful in improving accuracy of our
classifiers.

For our work with $A$ and $B$ section classification and matching, we use a
simple heuristic to split tunes into $A$ and $B$ sections as they are not
explicitly labelled in the data set. We first unfold all symbolic repeats in the
original tune, taking into consideration 1st and 2nd endings which very commonly
appear at the end of both $A$ and $B$ sections. This produces continuous streams
of music that are more easily analyzed, and reflect the structure of the tune as
it sounds when performed, rather than how it appears in notation.

Then, if the tune has a number of bars that is a multiple of 4, we split the
tune evenly in half. This is an imprecise heuristic, but should work well in
practice because $A$ and $B$ sections generally have the same number of bars as
they most commonly have parallel musical structure, and also because these
traditional tunes most commonly have 4-bar phrases within $A$ and $B$ sections.
See \cref{fig:drowsymusic} for an example.

\section{Preliminary classification experiments}

<<<<<<< HEAD
Before we implemented the heuristic to split tunes into $A$ and $B$ sections
and began classification experiments on these, we used an SVM to attempt to 
classify tunes into one of the 11 types of dances in our dataset (e.g. jigs,
reels). We did this to test our infrastructure (i.e. to make sure our ABC 
parser worked) as well as to get a sense of the viability of the $n$-gram
features described above. This also served as a useful benchmark of our data set
size (enough data to get meaningful results but not so much as to prohibit
timely training of our model). We found fairly mediocre classification results,
but we classified some types of dances reasonably well (e.g. we classified 
approximately 60\% of the polkas correctly), and we expect we would have done
better by improving some of the shortcomings of our feature extraction scheme 
(as described above).

After heuristically splitting our data into $A$ and $B$ sections, we trained
an SVM using a Gaussian kernel to classify sequences of notes as $A$ sections
or $B$ sections. We trained on 70\% of our dataset and tested the remaining 
30\%, and found the following promising results:

\begin{center}
\begin{tabular}{c|cc}
             & Predicted $A$ & Predicted $B$ \\ \hline
Actually $A$ & 2049          & 1325          \\
Actually $B$ & 1245          & 2130
\end{tabular}
\end{center}

We anticipate even better results for this classifier upon updating our
feature extraction because, for example, we believe that $B$ sections are
generally higher pitched than $A$ sections, and including information about
the octave of a note will make this more discernible to our classifier.

\end{document}
